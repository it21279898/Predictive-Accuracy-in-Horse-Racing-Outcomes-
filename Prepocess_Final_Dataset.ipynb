{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75162 entries, 0 to 75161\n",
      "Data columns (total 41 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   horse_id          75162 non-null  object \n",
      " 1   race_id           75162 non-null  object \n",
      " 2   race_name         75162 non-null  object \n",
      " 3   horse_name        75162 non-null  object \n",
      " 4   number            75162 non-null  object \n",
      " 5   sex               75070 non-null  object \n",
      " 6   age               75162 non-null  object \n",
      " 7   handicap_weight   75162 non-null  float64\n",
      " 8   jockey            75090 non-null  object \n",
      " 9   trainer           75161 non-null  object \n",
      " 10  win_odd_live      75162 non-null  float64\n",
      " 11  reference_odd     75162 non-null  float64\n",
      " 12  min_place_odd     75162 non-null  float64\n",
      " 13  max_place_odd     75162 non-null  float64\n",
      " 14  ze_show_odd       75162 non-null  float64\n",
      " 15  ze_4th_odd        75162 non-null  float64\n",
      " 16  music             75162 non-null  object \n",
      " 17  corde             75162 non-null  int64  \n",
      " 18  position          75162 non-null  int64  \n",
      " 19  date              75162 non-null  object \n",
      " 20  Start             75162 non-null  object \n",
      " 21  event_name        75162 non-null  object \n",
      " 22  race_type         75162 non-null  object \n",
      " 23  distance          75162 non-null  int64  \n",
      " 24  prize             75150 non-null  float64\n",
      " 25  field             75162 non-null  object \n",
      " 26  track             75162 non-null  object \n",
      " 27  corde.1           75162 non-null  object \n",
      " 28  penetrometer      75162 non-null  float64\n",
      " 29  number of horses  75162 non-null  int64  \n",
      " 30  race time         75162 non-null  float64\n",
      " 31  jockey_id         75162 non-null  object \n",
      " 32  trainer_id        75162 non-null  object \n",
      " 33  final_result_id   75162 non-null  object \n",
      " 34  1st               75162 non-null  object \n",
      " 35  2nd               75162 non-null  int64  \n",
      " 36  3rd               75162 non-null  int64  \n",
      " 37  4th               75162 non-null  int64  \n",
      " 38  5th               75162 non-null  int64  \n",
      " 39  6th               75162 non-null  int64  \n",
      " 40  7th               75162 non-null  int64  \n",
      "dtypes: float64(10), int64(10), object(21)\n",
      "memory usage: 23.5+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Temp\\ipykernel_21920\\794720883.py:2: DtypeWarning: Columns (34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\Final_horse_racing_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "merged_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\Final_horse_racing_dataset.csv')\n",
    "\n",
    "# Display the information about the dataset\n",
    "print(merged_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['horse_id', 'race_id', 'race_name', 'horse_name', 'number', 'sex',\n",
      "       'age', 'handicap_weight', 'jockey', 'trainer', 'win_odd_live',\n",
      "       'reference_odd', 'min_place_odd', 'max_place_odd', 'ze_show_odd',\n",
      "       'ze_4th_odd', 'music', 'corde', 'position', 'date', 'Start',\n",
      "       'event_name', 'race_type', 'distance', 'prize', 'field', 'track',\n",
      "       'corde.1', 'penetrometer', 'number of horses', 'race time', 'jockey_id',\n",
      "       'trainer_id', 'final_result_id', '1st', '2nd', '3rd', '4th', '5th',\n",
      "       '6th', '7th'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: Index(['number', 'sex', 'age', 'handicap_weight', 'jockey', 'trainer',\n",
      "       'win_odd_live', 'reference_odd', 'min_place_odd', 'max_place_odd',\n",
      "       'ze_show_odd', 'ze_4th_odd', 'music', 'corde', 'position', 'date',\n",
      "       'Start', 'race_type', 'distance', 'prize', 'field', 'track',\n",
      "       'penetrometer', 'number of horses', 'race time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `merged_df` is your DataFrame\n",
    "# Define columns to drop\n",
    "columns_to_drop = [\n",
    "    'race_id', 'horse_id', 'jockey_id', 'trainer_id', 'final_result_id',\n",
    "    'race_name', 'horse_name', 'event_name', 'corde.1', '1st', '2nd', '3rd',\n",
    "    '4th', '5th', '6th', '7th'\n",
    "]\n",
    "\n",
    "# Drop columns\n",
    "merged_df = merged_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Check the remaining columns\n",
    "print(\"Remaining columns:\", merged_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  number sex age  handicap_weight         jockey                      trainer  \\\n",
      "0      1   H   2             57.0      Demuro C.                     Brogi S.   \n",
      "1      2   F   2             55.5   Roussel Ale.                  Monfort Ed.   \n",
      "2      3   M   2             55.5  Murzabayev B.  Janackova Koplikova Mlle I.   \n",
      "3      4   M   2             55.5       Guyon M.                 Vermeulen F.   \n",
      "4      5   M   2             55.5     Besnier H.  Janackova Koplikova Mlle I.   \n",
      "\n",
      "   win_odd_live  reference_odd  min_place_odd  max_place_odd  ...        date  \\\n",
      "0           3.1            3.0            1.3            1.8  ...  26/08/2023   \n",
      "1           4.4            5.1            1.8            2.4  ...  26/08/2023   \n",
      "2           2.9            3.1            1.3            1.8  ...  26/08/2023   \n",
      "3           6.7            6.1            3.0            4.2  ...  26/08/2023   \n",
      "4          15.4           14.6            5.5            7.6  ...  26/08/2023   \n",
      "\n",
      "   Start race_type  distance    prize   field  track penetrometer  \\\n",
      "0  13h23      Plat      1800  34000.0  Souple  Herbe          3.6   \n",
      "1  13h23      Plat      1800  34000.0  Souple  Herbe          3.6   \n",
      "2  13h23      Plat      1800  34000.0  Souple  Herbe          3.6   \n",
      "3  13h23      Plat      1800  34000.0  Souple  Herbe          3.6   \n",
      "4  13h23      Plat      1800  34000.0  Souple  Herbe          3.6   \n",
      "\n",
      "   number of horses  race time  \n",
      "0                 6      115.6  \n",
      "1                 6      115.6  \n",
      "2                 6      115.6  \n",
      "3                 6      115.6  \n",
      "4                 6      115.6  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the first few rows to verify the scaling\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number               0\n",
      "sex                 92\n",
      "age                  0\n",
      "handicap_weight      0\n",
      "jockey              72\n",
      "trainer              1\n",
      "win_odd_live         0\n",
      "reference_odd        0\n",
      "min_place_odd        0\n",
      "max_place_odd        0\n",
      "ze_show_odd          0\n",
      "ze_4th_odd           0\n",
      "music                0\n",
      "corde                0\n",
      "position             0\n",
      "date                 0\n",
      "Start                0\n",
      "race_type            0\n",
      "distance             0\n",
      "prize               12\n",
      "field                0\n",
      "track                0\n",
      "penetrometer         0\n",
      "number of horses     0\n",
      "race time            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex        92\n",
      "jockey     72\n",
      "trainer     1\n",
      "prize      12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = merged_df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])  # Display columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in numerical columns with the mean\n",
    "merged_df['prize'].fillna(merged_df['prize'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in categorical columns with the mode\n",
    "merged_df['sex'].fillna(merged_df['sex'].mode()[0], inplace=True)\n",
    "merged_df['jockey'].fillna(merged_df['jockey'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'trainer' is missing (only 1 value here, but for illustration)\n",
    "merged_df.dropna(subset=['trainer'], inplace=True)\n",
    "\n",
    "# Alternatively, drop entire column if it has too many missing values:\n",
    "if missing_values['jockey'] / len(merged_df) > 0.3:  # Example threshold of 30%\n",
    "    merged_df.drop(columns=['jockey'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check again for any remaining missing values\n",
    "missing_values_after = merged_df.isnull().sum()\n",
    "print(missing_values_after[missing_values_after > 0])  # Should return an empty series if all handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     75161\n",
      "unique       14\n",
      "top           3\n",
      "freq      19007\n",
      "Name: age, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check for outliers or erroneous data (e.g., negative ages)\n",
    "# Example: Check age column\n",
    "print(merged_df['age'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape after removing erroneous entries: (75051, 25)\n"
     ]
    }
   ],
   "source": [
    "# Convert 'age' to numeric if it's not already (handle errors by coercing them to NaN)\n",
    "merged_df['age'] = pd.to_numeric(merged_df['age'], errors='coerce')\n",
    "\n",
    "# Remove rows with negative ages or NaN values after conversion\n",
    "merged_df = merged_df[merged_df['age'] >= 0]\n",
    "\n",
    "# Check the shape after cleaning\n",
    "print(f\"DataFrame shape after removing erroneous entries: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining missing values\n",
    "missing_values_after = merged_df.isnull().sum()\n",
    "print(missing_values_after[missing_values_after > 0])  # Should return an empty series if all handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 75051 entries, 0 to 75161\n",
      "Data columns (total 25 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   number            75051 non-null  object \n",
      " 1   sex               75051 non-null  object \n",
      " 2   age               75051 non-null  float64\n",
      " 3   handicap_weight   75051 non-null  float64\n",
      " 4   jockey            75051 non-null  object \n",
      " 5   trainer           75051 non-null  object \n",
      " 6   win_odd_live      75051 non-null  float64\n",
      " 7   reference_odd     75051 non-null  float64\n",
      " 8   min_place_odd     75051 non-null  float64\n",
      " 9   max_place_odd     75051 non-null  float64\n",
      " 10  ze_show_odd       75051 non-null  float64\n",
      " 11  ze_4th_odd        75051 non-null  float64\n",
      " 12  music             75051 non-null  object \n",
      " 13  corde             75051 non-null  int64  \n",
      " 14  position          75051 non-null  int64  \n",
      " 15  date              75051 non-null  object \n",
      " 16  Start             75051 non-null  object \n",
      " 17  race_type         75051 non-null  object \n",
      " 18  distance          75051 non-null  int64  \n",
      " 19  prize             75051 non-null  float64\n",
      " 20  field             75051 non-null  object \n",
      " 21  track             75051 non-null  object \n",
      " 22  penetrometer      75051 non-null  float64\n",
      " 23  number of horses  75051 non-null  int64  \n",
      " 24  race time         75051 non-null  float64\n",
      "dtypes: float64(11), int64(4), object(10)\n",
      "memory usage: 14.9+ MB\n",
      "None\n",
      "  number sex  age  handicap_weight         jockey  \\\n",
      "0      1   H  2.0             57.0      Demuro C.   \n",
      "1      2   F  2.0             55.5   Roussel Ale.   \n",
      "2      3   M  2.0             55.5  Murzabayev B.   \n",
      "3      4   M  2.0             55.5       Guyon M.   \n",
      "4      5   M  2.0             55.5     Besnier H.   \n",
      "\n",
      "                       trainer  win_odd_live  reference_odd  min_place_odd  \\\n",
      "0                     Brogi S.           3.1            3.0            1.3   \n",
      "1                  Monfort Ed.           4.4            5.1            1.8   \n",
      "2  Janackova Koplikova Mlle I.           2.9            3.1            1.3   \n",
      "3                 Vermeulen F.           6.7            6.1            3.0   \n",
      "4  Janackova Koplikova Mlle I.          15.4           14.6            5.5   \n",
      "\n",
      "   max_place_odd  ...        date  Start race_type  distance    prize   field  \\\n",
      "0            1.8  ...  26/08/2023  13h23      Plat      1800  34000.0  Souple   \n",
      "1            2.4  ...  26/08/2023  13h23      Plat      1800  34000.0  Souple   \n",
      "2            1.8  ...  26/08/2023  13h23      Plat      1800  34000.0  Souple   \n",
      "3            4.2  ...  26/08/2023  13h23      Plat      1800  34000.0  Souple   \n",
      "4            7.6  ...  26/08/2023  13h23      Plat      1800  34000.0  Souple   \n",
      "\n",
      "   track penetrometer  number of horses  race time  \n",
      "0  Herbe          3.6                 6      115.6  \n",
      "1  Herbe          3.6                 6      115.6  \n",
      "2  Herbe          3.6                 6      115.6  \n",
      "3  Herbe          3.6                 6      115.6  \n",
      "4  Herbe          3.6                 6      115.6  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the cleaned DataFrame\n",
    "print(merged_df.info())\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['number', 'sex', 'age', 'handicap_weight', 'jockey', 'trainer',\n",
      "       'win_odd_live', 'reference_odd', 'min_place_odd', 'max_place_odd',\n",
      "       'ze_show_odd', 'ze_4th_odd', 'music', 'corde', 'position', 'date',\n",
      "       'Start', 'race_type', 'distance', 'prize', 'field', 'track',\n",
      "       'penetrometer', 'number of horses', 'race time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_cols = ['sex', 'jockey', 'trainer', 'race_type', 'track', 'music', 'corde']\n",
    "\n",
    "# Dictionary to store encoders for each categorical column\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode each categorical column\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    merged_df[col] = le.fit_transform(merged_df[col].astype(str))  # Encode and convert to string if needed\n",
    "    label_encoders[col] = le  # Save encoder if needed for future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Temp\\ipykernel_21920\\3043809910.py:2: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  merged_df['date'] = pd.to_datetime(merged_df['date'])\n"
     ]
    }
   ],
   "source": [
    "# Convert date to datetime format and extract year, month, and day\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "merged_df['year'] = merged_df['date'].dt.year\n",
    "merged_df['month'] = merged_df['date'].dt.month\n",
    "merged_df['day'] = merged_df['date'].dt.day\n",
    "\n",
    "# Drop the original 'date' column if it's no longer needed\n",
    "merged_df = merged_df.drop(columns=['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Unknown' in the 'age' column with 0\n",
    "merged_df['age'] = merged_df['age'].replace('Unknown', 0)\n",
    "\n",
    "# Ensure 'age' column is in numeric format\n",
    "merged_df['age'] = merged_df['age'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# List of numerical columns to scale\n",
    "numerical_cols = ['age', 'handicap_weight', 'distance', 'prize', 'penetrometer', 'number of horses', 'race time']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the numerical columns and transform them\n",
    "merged_df[numerical_cols] = scaler.fit_transform(merged_df[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# List of numerical columns to scale\n",
    "numerical_cols = ['age', 'handicap_weight', 'distance', 'prize', 'penetrometer', 'number of horses', 'race time']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the numerical columns and transform them\n",
    "merged_df[numerical_cols] = scaler.fit_transform(merged_df[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary target for predicting top 3 horses\n",
    "merged_df['top_3'] = merged_df['position'].apply(lambda x: 1 if x in [1, 2, 3] else 0)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = merged_df.drop(columns=['position', 'top_3'])  # Drop 'position' and other unused columns\n",
    "y = merged_df['top_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['number', 'Start', 'field'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on categorical columns\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Ensure that the train and test sets have the same columns after encoding\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7630404370128573\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85     11092\n",
      "           1       0.60      0.28      0.38      3919\n",
      "\n",
      "    accuracy                           0.76     15011\n",
      "   macro avg       0.69      0.61      0.62     15011\n",
      "weighted avg       0.74      0.76      0.73     15011\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10361   731]\n",
      " [ 2826  1093]]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
