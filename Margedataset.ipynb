{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV files into DataFrames\n",
    "horses_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\horses.csv')\n",
    "jockeys_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\jockeys.csv')\n",
    "races_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\races.csv')\n",
    "trainers_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\trainers.csv')\n",
    "winnings_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\winnings.csv')\n",
    "final_results_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\final_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge horses with races\n",
    "merged_df = pd.merge(horses_df, races_df, on='race_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the result with jockeys\n",
    "merged_df = pd.merge(merged_df, jockeys_df, on=['race_id', 'horse_id'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'race_name' in trainers_df to avoid conflict\n",
    "trainers_df = trainers_df.rename(columns={'race_name': 'trainer_race_name'})\n",
    "\n",
    "# Now merge without conflicts\n",
    "merged_df = pd.merge(merged_df, trainers_df, on=['race_id', 'horse_id', 'jockey_id'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'race_name' in final_results_df to avoid conflict\n",
    "final_results_df = final_results_df.rename(columns={'race_name': 'final_race_name'})\n",
    "\n",
    "# Now merge without conflicts\n",
    "merged_df = pd.merge(merged_df, final_results_df, on='race_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.to_csv(r'C:\\Users\\sujit\\OneDrive - Sri Lanka Institute of Information Technology\\Research SLIIT\\Research Project\\Dataset\\merged_horse_racing_data4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Temp\\ipykernel_17592\\3875104938.py:1: DtypeWarning: Columns (4,6,35,49,61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\merged_horse_racing_data4.csv')\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\merged_horse_racing_data4.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  horse_id race_id                     race_name     horse_name number sex  \\\n",
      "0      H_1     R_1  Prix Zeturf (Prix North Jet)       MARSELAN      1   H   \n",
      "1      H_2     R_1  Prix Zeturf (Prix North Jet)    HASHTAG JOA      2   F   \n",
      "2      H_3     R_1  Prix Zeturf (Prix North Jet)          GABON      3   M   \n",
      "3      H_4     R_1  Prix Zeturf (Prix North Jet)  SACHA SUNRISE      4   M   \n",
      "4      H_5     R_1  Prix Zeturf (Prix North Jet)         ZABYAK      5   M   \n",
      "\n",
      "  age  handicap_weight         jockey                      trainer  ...  \\\n",
      "0   2             57.0      Demuro C.                     Brogi S.  ...   \n",
      "1   2             55.5   Roussel Ale.                  Monfort Ed.  ...   \n",
      "2   2             55.5  Murzabayev B.  Janackova Koplikova Mlle I.  ...   \n",
      "3   2             55.5       Guyon M.                 Vermeulen F.  ...   \n",
      "4   2             55.5     Besnier H.  Janackova Koplikova Mlle I.  ...   \n",
      "\n",
      "   position.2  final_result_id               final_race_name  1st  2nd  3rd  \\\n",
      "0           1             FR_1  Prix Zeturf (Prix North Jet)    1    3    4   \n",
      "1           4             FR_1  Prix Zeturf (Prix North Jet)    1    3    4   \n",
      "2           2             FR_1  Prix Zeturf (Prix North Jet)    1    3    4   \n",
      "3           3             FR_1  Prix Zeturf (Prix North Jet)    1    3    4   \n",
      "4           5             FR_1  Prix Zeturf (Prix North Jet)    1    3    4   \n",
      "\n",
      "  4th  5th  6th 7th  \n",
      "0   2    5    7   0  \n",
      "1   2    5    7   0  \n",
      "2   2    5    7   0  \n",
      "3   2    5    7   0  \n",
      "4   2    5    7   0  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())  # Shows the first 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['horse_id', 'race_id', 'race_name', 'horse_name', 'number', 'sex',\n",
      "       'age', 'handicap_weight', 'jockey', 'trainer', 'win_odd_live',\n",
      "       'reference_odd', 'min_place_odd', 'max_place_odd', 'ze_show_odd',\n",
      "       'ze_4th_odd', 'music', 'corde', 'position', 'date', 'Start',\n",
      "       'event_name', 'race_name.1', 'race_type', 'distance', 'prize', 'field',\n",
      "       'track', 'corde.1', 'penetrometer', 'number of horses', 'race time',\n",
      "       'jockey_id', 'jockey_name', 'race_name.2', 'horse_number',\n",
      "       'horse_name.1', 'handicap_weight.1', 'win_odd_live.1',\n",
      "       'reference_odd.1', 'min_place_odd.1', 'max_place_odd.1',\n",
      "       'ze_show_odd.1', 'ze_4th_odd.1', 'position.1', 'trainer_id',\n",
      "       'trainer_name', 'jockey_name.1', 'trainer_race_name', 'horse_number.1',\n",
      "       'horse_name.2', 'handicap_weight.2', 'win_odd_live.2',\n",
      "       'reference_odd.2', 'min_place_odd.2', 'max_place_odd.2',\n",
      "       'ze_show_odd.2', 'ze_4th_odd.2', 'position.2', 'final_result_id',\n",
      "       'final_race_name', '1st', '2nd', '3rd', '4th', '5th', '6th', '7th'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)  # Check which columns remain after dropping duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate columns based on their names\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with duplicate content\n",
    "merged_df = merged_df.T.drop_duplicates().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['horse_id', 'race_id', 'race_name', 'horse_name', 'number', 'sex',\n",
      "       'age', 'handicap_weight', 'jockey', 'trainer', 'win_odd_live',\n",
      "       'reference_odd', 'min_place_odd', 'max_place_odd', 'ze_show_odd',\n",
      "       'ze_4th_odd', 'music', 'corde', 'position', 'date', 'Start',\n",
      "       'event_name', 'race_type', 'distance', 'prize', 'field', 'track',\n",
      "       'corde.1', 'penetrometer', 'number of horses', 'race time', 'jockey_id',\n",
      "       'trainer_id', 'final_result_id', '1st', '2nd', '3rd', '4th', '5th',\n",
      "       '6th', '7th'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)  # Check which columns remain after dropping duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       horse_id race_id                     race_name        horse_name number  \\\n",
      "0          H_1     R_1  Prix Zeturf (Prix North Jet)          MARSELAN      1   \n",
      "1          H_2     R_1  Prix Zeturf (Prix North Jet)       HASHTAG JOA      2   \n",
      "2          H_3     R_1  Prix Zeturf (Prix North Jet)             GABON      3   \n",
      "3          H_4     R_1  Prix Zeturf (Prix North Jet)     SACHA SUNRISE      4   \n",
      "4          H_5     R_1  Prix Zeturf (Prix North Jet)            ZABYAK      5   \n",
      "...        ...     ...                           ...               ...    ...   \n",
      "75157  H_75158  R_6548           Prix Javier Nino H.      WINNER STATE     11   \n",
      "75158  H_75159  R_6548           Prix Javier Nino H.     REO POR LINDO     12   \n",
      "75159  H_75160  R_6548           Prix Javier Nino H.           DEMENTE     13   \n",
      "75160  H_75161  R_6548           Prix Javier Nino H.        MI MARTUCA     14   \n",
      "75161  H_75162  R_6548           Prix Javier Nino H.  LORD OF THE WIND     15   \n",
      "\n",
      "      sex age handicap_weight                      jockey  \\\n",
      "0       H   2            57.0                   Demuro C.   \n",
      "1       F   2            55.5                Roussel Ale.   \n",
      "2       M   2            55.5               Murzabayev B.   \n",
      "3       M   2            55.5                    Guyon M.   \n",
      "4       M   2            55.5                  Besnier H.   \n",
      "...    ..  ..             ...                         ...   \n",
      "75157   H   8            53.0                  S Gonzalez   \n",
      "75158   M   8            56.0      Santibanez Chavez Nic.   \n",
      "75159   H   4            52.0  Carrasco Rodriguez Die. F.   \n",
      "75160   F   8            57.0                     Leon W.   \n",
      "75161   M   5            56.0                 Vargas Wil.   \n",
      "\n",
      "                             trainer  ... jockey_id trainer_id  \\\n",
      "0                           Brogi S.  ...       J_1        T_1   \n",
      "1                        Monfort Ed.  ...       J_2        T_2   \n",
      "2        Janackova Koplikova Mlle I.  ...       J_3        T_3   \n",
      "3                       Vermeulen F.  ...       J_4        T_4   \n",
      "4        Janackova Koplikova Mlle I.  ...       J_5        T_3   \n",
      "...                              ...  ...       ...        ...   \n",
      "75157  Raul Andres Montesino Serrano  ...     J_359     T_1082   \n",
      "75158             Aldo Rodolfo Parra  ...     J_327      T_442   \n",
      "75159                    R Montesino  ...     J_363     T_1066   \n",
      "75160  Juan Pablo Rodriguez Riquelme  ...     J_331     T_1098   \n",
      "75161             Aldo Rodolfo Parra  ...     J_857      T_442   \n",
      "\n",
      "      final_result_id 1st 2nd 3rd 4th 5th 6th 7th  \n",
      "0                FR_1   1   3   4   2   5   7   0  \n",
      "1                FR_1   1   3   4   2   5   7   0  \n",
      "2                FR_1   1   3   4   2   5   7   0  \n",
      "3                FR_1   1   3   4   2   5   7   0  \n",
      "4                FR_1   1   3   4   2   5   7   0  \n",
      "...               ...  ..  ..  ..  ..  ..  ..  ..  \n",
      "75157         FR_6548  10   5   3  12   2   7   4  \n",
      "75158         FR_6548  10   5   3  12   2   7   4  \n",
      "75159         FR_6548  10   5   3  12   2   7   4  \n",
      "75160         FR_6548  10   5   3  12   2   7   4  \n",
      "75161         FR_6548  10   5   3  12   2   7   4  \n",
      "\n",
      "[75162 rows x 41 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head)  # Check which columns remain after dropping duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.to_csv(r'C:\\Users\\sujit\\OneDrive - Sri Lanka Institute of Information Technology\\Research SLIIT\\Research Project\\Dataset\\Final_horse_racing_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Temp\\ipykernel_17592\\50200906.py:1: DtypeWarning: Columns (34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\Final_horse_racing_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.read_csv('C:\\\\Users\\\\sujit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research SLIIT\\\\Research Project\\\\Dataset\\\\Final_horse_racing_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  horse_id race_id                     race_name     horse_name number sex  \\\n",
      "0      H_1     R_1  Prix Zeturf (Prix North Jet)       MARSELAN      1   H   \n",
      "1      H_2     R_1  Prix Zeturf (Prix North Jet)    HASHTAG JOA      2   F   \n",
      "2      H_3     R_1  Prix Zeturf (Prix North Jet)          GABON      3   M   \n",
      "3      H_4     R_1  Prix Zeturf (Prix North Jet)  SACHA SUNRISE      4   M   \n",
      "4      H_5     R_1  Prix Zeturf (Prix North Jet)         ZABYAK      5   M   \n",
      "\n",
      "  age  handicap_weight         jockey                      trainer  ...  \\\n",
      "0   2             57.0      Demuro C.                     Brogi S.  ...   \n",
      "1   2             55.5   Roussel Ale.                  Monfort Ed.  ...   \n",
      "2   2             55.5  Murzabayev B.  Janackova Koplikova Mlle I.  ...   \n",
      "3   2             55.5       Guyon M.                 Vermeulen F.  ...   \n",
      "4   2             55.5     Besnier H.  Janackova Koplikova Mlle I.  ...   \n",
      "\n",
      "   jockey_id  trainer_id  final_result_id  1st  2nd  3rd 4th  5th  6th 7th  \n",
      "0        J_1         T_1             FR_1    1    3    4   2    5    7   0  \n",
      "1        J_2         T_2             FR_1    1    3    4   2    5    7   0  \n",
      "2        J_3         T_3             FR_1    1    3    4   2    5    7   0  \n",
      "3        J_4         T_4             FR_1    1    3    4   2    5    7   0  \n",
      "4        J_5         T_3             FR_1    1    3    4   2    5    7   0  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75162 entries, 0 to 75161\n",
      "Data columns (total 41 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   horse_id          75162 non-null  object \n",
      " 1   race_id           75162 non-null  object \n",
      " 2   race_name         75162 non-null  object \n",
      " 3   horse_name        75162 non-null  object \n",
      " 4   number            75162 non-null  object \n",
      " 5   sex               75070 non-null  object \n",
      " 6   age               75162 non-null  object \n",
      " 7   handicap_weight   75162 non-null  float64\n",
      " 8   jockey            75090 non-null  object \n",
      " 9   trainer           75161 non-null  object \n",
      " 10  win_odd_live      75162 non-null  float64\n",
      " 11  reference_odd     75162 non-null  float64\n",
      " 12  min_place_odd     75162 non-null  float64\n",
      " 13  max_place_odd     75162 non-null  float64\n",
      " 14  ze_show_odd       75162 non-null  float64\n",
      " 15  ze_4th_odd        75162 non-null  float64\n",
      " 16  music             75162 non-null  object \n",
      " 17  corde             75162 non-null  int64  \n",
      " 18  position          75162 non-null  int64  \n",
      " 19  date              75162 non-null  object \n",
      " 20  Start             75162 non-null  object \n",
      " 21  event_name        75162 non-null  object \n",
      " 22  race_type         75162 non-null  object \n",
      " 23  distance          75162 non-null  int64  \n",
      " 24  prize             75150 non-null  float64\n",
      " 25  field             75162 non-null  object \n",
      " 26  track             75162 non-null  object \n",
      " 27  corde.1           75162 non-null  object \n",
      " 28  penetrometer      75162 non-null  float64\n",
      " 29  number of horses  75162 non-null  int64  \n",
      " 30  race time         75162 non-null  float64\n",
      " 31  jockey_id         75162 non-null  object \n",
      " 32  trainer_id        75162 non-null  object \n",
      " 33  final_result_id   75162 non-null  object \n",
      " 34  1st               75162 non-null  object \n",
      " 35  2nd               75162 non-null  int64  \n",
      " 36  3rd               75162 non-null  int64  \n",
      " 37  4th               75162 non-null  int64  \n",
      " 38  5th               75162 non-null  int64  \n",
      " 39  6th               75162 non-null  int64  \n",
      " 40  7th               75162 non-null  int64  \n",
      "dtypes: float64(10), int64(10), object(21)\n",
      "memory usage: 23.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())\n",
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       horse_id race_id                     race_name        horse_name number  \\\n",
      "0          H_1     R_1  Prix Zeturf (Prix North Jet)          MARSELAN      1   \n",
      "1          H_2     R_1  Prix Zeturf (Prix North Jet)       HASHTAG JOA      2   \n",
      "2          H_3     R_1  Prix Zeturf (Prix North Jet)             GABON      3   \n",
      "3          H_4     R_1  Prix Zeturf (Prix North Jet)     SACHA SUNRISE      4   \n",
      "4          H_5     R_1  Prix Zeturf (Prix North Jet)            ZABYAK      5   \n",
      "...        ...     ...                           ...               ...    ...   \n",
      "75157  H_75158  R_6548           Prix Javier Nino H.      WINNER STATE     11   \n",
      "75158  H_75159  R_6548           Prix Javier Nino H.     REO POR LINDO     12   \n",
      "75159  H_75160  R_6548           Prix Javier Nino H.           DEMENTE     13   \n",
      "75160  H_75161  R_6548           Prix Javier Nino H.        MI MARTUCA     14   \n",
      "75161  H_75162  R_6548           Prix Javier Nino H.  LORD OF THE WIND     15   \n",
      "\n",
      "      sex age  handicap_weight                      jockey  \\\n",
      "0       H   2             57.0                   Demuro C.   \n",
      "1       F   2             55.5                Roussel Ale.   \n",
      "2       M   2             55.5               Murzabayev B.   \n",
      "3       M   2             55.5                    Guyon M.   \n",
      "4       M   2             55.5                  Besnier H.   \n",
      "...    ..  ..              ...                         ...   \n",
      "75157   H   8             53.0                  S Gonzalez   \n",
      "75158   M   8             56.0      Santibanez Chavez Nic.   \n",
      "75159   H   4             52.0  Carrasco Rodriguez Die. F.   \n",
      "75160   F   8             57.0                     Leon W.   \n",
      "75161   M   5             56.0                 Vargas Wil.   \n",
      "\n",
      "                             trainer  ...  jockey_id  trainer_id  \\\n",
      "0                           Brogi S.  ...        J_1         T_1   \n",
      "1                        Monfort Ed.  ...        J_2         T_2   \n",
      "2        Janackova Koplikova Mlle I.  ...        J_3         T_3   \n",
      "3                       Vermeulen F.  ...        J_4         T_4   \n",
      "4        Janackova Koplikova Mlle I.  ...        J_5         T_3   \n",
      "...                              ...  ...        ...         ...   \n",
      "75157  Raul Andres Montesino Serrano  ...      J_359      T_1082   \n",
      "75158             Aldo Rodolfo Parra  ...      J_327       T_442   \n",
      "75159                    R Montesino  ...      J_363      T_1066   \n",
      "75160  Juan Pablo Rodriguez Riquelme  ...      J_331      T_1098   \n",
      "75161             Aldo Rodolfo Parra  ...      J_857       T_442   \n",
      "\n",
      "       final_result_id  1st  2nd  3rd 4th  5th  6th 7th  \n",
      "0                 FR_1    1    3    4   2    5    7   0  \n",
      "1                 FR_1    1    3    4   2    5    7   0  \n",
      "2                 FR_1    1    3    4   2    5    7   0  \n",
      "3                 FR_1    1    3    4   2    5    7   0  \n",
      "4                 FR_1    1    3    4   2    5    7   0  \n",
      "...                ...  ...  ...  ...  ..  ...  ...  ..  \n",
      "75157          FR_6548   10    5    3  12    2    7   4  \n",
      "75158          FR_6548   10    5    3  12    2    7   4  \n",
      "75159          FR_6548   10    5    3  12    2    7   4  \n",
      "75160          FR_6548   10    5    3  12    2    7   4  \n",
      "75161          FR_6548   10    5    3  12    2    7   4  \n",
      "\n",
      "[75162 rows x 41 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head)  # Check which columns remain after dropping duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse_id             0\n",
      "race_id              0\n",
      "race_name            0\n",
      "horse_name           0\n",
      "number               0\n",
      "sex                 92\n",
      "age                  0\n",
      "handicap_weight      0\n",
      "jockey              72\n",
      "trainer              1\n",
      "win_odd_live         0\n",
      "reference_odd        0\n",
      "min_place_odd        0\n",
      "max_place_odd        0\n",
      "ze_show_odd          0\n",
      "ze_4th_odd           0\n",
      "music                0\n",
      "corde                0\n",
      "position             0\n",
      "date                 0\n",
      "Start                0\n",
      "event_name           0\n",
      "race_type            0\n",
      "distance             0\n",
      "prize               12\n",
      "field                0\n",
      "track                0\n",
      "corde.1              0\n",
      "penetrometer         0\n",
      "number of horses     0\n",
      "race time            0\n",
      "jockey_id            0\n",
      "trainer_id           0\n",
      "final_result_id      0\n",
      "1st                  0\n",
      "2nd                  0\n",
      "3rd                  0\n",
      "4th                  0\n",
      "5th                  0\n",
      "6th                  0\n",
      "7th                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'prize' with the mean\n",
    "merged_df['prize'].fillna(merged_df['prize'].mean(), inplace=True)\n",
    "\n",
    "# Alternatively, fill missing values in 'prize' with the median\n",
    "merged_df['prize'].fillna(merged_df['prize'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'jockey' with 'Unknown'\n",
    "merged_df['jockey'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'sex' with 'Unknown'\n",
    "merged_df['sex'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'trainer' with 'Unknown'\n",
    "merged_df['trainer'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse_id            0\n",
      "race_id             0\n",
      "race_name           0\n",
      "horse_name          0\n",
      "number              0\n",
      "sex                 0\n",
      "age                 0\n",
      "handicap_weight     0\n",
      "jockey              0\n",
      "trainer             0\n",
      "win_odd_live        0\n",
      "reference_odd       0\n",
      "min_place_odd       0\n",
      "max_place_odd       0\n",
      "ze_show_odd         0\n",
      "ze_4th_odd          0\n",
      "music               0\n",
      "corde               0\n",
      "position            0\n",
      "date                0\n",
      "Start               0\n",
      "event_name          0\n",
      "race_type           0\n",
      "distance            0\n",
      "prize               0\n",
      "field               0\n",
      "track               0\n",
      "corde.1             0\n",
      "penetrometer        0\n",
      "number of horses    0\n",
      "race time           0\n",
      "jockey_id           0\n",
      "trainer_id          0\n",
      "final_result_id     0\n",
      "1st                 0\n",
      "2nd                 0\n",
      "3rd                 0\n",
      "4th                 0\n",
      "5th                 0\n",
      "6th                 0\n",
      "7th                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any missing values left\n",
    "print(merged_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse_id             object\n",
      "race_id              object\n",
      "race_name            object\n",
      "horse_name           object\n",
      "number               object\n",
      "sex                  object\n",
      "age                  object\n",
      "handicap_weight     float64\n",
      "jockey               object\n",
      "trainer              object\n",
      "win_odd_live        float64\n",
      "reference_odd       float64\n",
      "min_place_odd       float64\n",
      "max_place_odd       float64\n",
      "ze_show_odd         float64\n",
      "ze_4th_odd          float64\n",
      "music                object\n",
      "corde                 int64\n",
      "position              int64\n",
      "date                 object\n",
      "Start                object\n",
      "event_name           object\n",
      "race_type            object\n",
      "distance              int64\n",
      "prize               float64\n",
      "field                object\n",
      "track                object\n",
      "corde.1              object\n",
      "penetrometer        float64\n",
      "number of horses      int64\n",
      "race time           float64\n",
      "jockey_id            object\n",
      "trainer_id           object\n",
      "final_result_id      object\n",
      "1st                  object\n",
      "2nd                   int64\n",
      "3rd                   int64\n",
      "4th                   int64\n",
      "5th                   int64\n",
      "6th                   int64\n",
      "7th                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check current data types\n",
    "print(merged_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Unknown' with 0 in the 'age' column\n",
    "merged_df['age'].replace('Unknown', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'age' to numeric and handle any remaining non-numeric entries\n",
    "merged_df['age'] = pd.to_numeric(merged_df['age'], errors='coerce')\n",
    "\n",
    "# Now, fill any remaining NaN values with 0\n",
    "merged_df['age'].fillna(0, inplace=True)\n",
    "\n",
    "# Finally, convert 'age' to int\n",
    "merged_df['age'] = merged_df['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse_id                    object\n",
      "race_id                     object\n",
      "race_name                 category\n",
      "horse_name                category\n",
      "number                    category\n",
      "sex                       category\n",
      "age                          int32\n",
      "handicap_weight            float64\n",
      "jockey                    category\n",
      "trainer                   category\n",
      "win_odd_live               float64\n",
      "reference_odd              float64\n",
      "min_place_odd              float64\n",
      "max_place_odd              float64\n",
      "ze_show_odd                float64\n",
      "ze_4th_odd                 float64\n",
      "music                     category\n",
      "corde                        int64\n",
      "position                     int64\n",
      "date                datetime64[ns]\n",
      "Start               datetime64[ns]\n",
      "event_name                category\n",
      "race_type                 category\n",
      "distance                     int64\n",
      "prize                      float64\n",
      "field                       object\n",
      "track                       object\n",
      "corde.1                     object\n",
      "penetrometer               float64\n",
      "number of horses             int64\n",
      "race time                  float64\n",
      "jockey_id                   object\n",
      "trainer_id                  object\n",
      "final_result_id             object\n",
      "1st                         object\n",
      "2nd                          int64\n",
      "3rd                          int64\n",
      "4th                          int64\n",
      "5th                          int64\n",
      "6th                          int64\n",
      "7th                          int64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Temp\\ipykernel_17592\\2563754893.py:13: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  merged_df['date'] = pd.to_datetime(merged_df['date'], errors='coerce')  # Convert to datetime\n",
      "C:\\Users\\sujit\\AppData\\Local\\Temp\\ipykernel_17592\\2563754893.py:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_df['Start'] = pd.to_datetime(merged_df['Start'], errors='coerce')  # Convert to datetime\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_df is already defined\n",
    "\n",
    "# Convert columns to appropriate types\n",
    "merged_df['number'] = merged_df['number'].astype('category')  # Convert 'number' to category\n",
    "merged_df['race_name'] = merged_df['race_name'].astype('category')\n",
    "merged_df['horse_name'] = merged_df['horse_name'].astype('category')\n",
    "merged_df['sex'] = merged_df['sex'].astype('category')\n",
    "merged_df['jockey'] = merged_df['jockey'].astype('category')\n",
    "merged_df['trainer'] = merged_df['trainer'].astype('category')\n",
    "merged_df['music'] = merged_df['music'].astype('category')\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date'], errors='coerce')  # Convert to datetime\n",
    "merged_df['Start'] = pd.to_datetime(merged_df['Start'], errors='coerce')  # Convert to datetime\n",
    "merged_df['event_name'] = merged_df['event_name'].astype('category')\n",
    "merged_df['race_type'] = merged_df['race_type'].astype('category')\n",
    "\n",
    "# Check the new data types\n",
    "print(merged_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75162, 121182)\n",
      "  horse_id race_id number  age  handicap_weight  win_odd_live  reference_odd  \\\n",
      "0      H_1     R_1      1    2             57.0           3.1            3.0   \n",
      "1      H_2     R_1      2    2             55.5           4.4            5.1   \n",
      "2      H_3     R_1      3    2             55.5           2.9            3.1   \n",
      "3      H_4     R_1      4    2             55.5           6.7            6.1   \n",
      "4      H_5     R_1      5    2             55.5          15.4           14.6   \n",
      "\n",
      "   min_place_odd  max_place_odd  ze_show_odd  ...  horse_name_ZWIALH  \\\n",
      "0            1.3            1.8          5.0  ...              False   \n",
      "1            1.8            2.4          3.4  ...              False   \n",
      "2            1.3            1.8          3.6  ...              False   \n",
      "3            3.0            4.2          4.2  ...              False   \n",
      "4            5.5            7.6          8.1  ...              False   \n",
      "\n",
      "   horse_name_ZYGARDE  horse_name_ZYGFRYD race_type_Cross  \\\n",
      "0               False               False           False   \n",
      "1               False               False           False   \n",
      "2               False               False           False   \n",
      "3               False               False           False   \n",
      "4               False               False           False   \n",
      "\n",
      "  race_type_Cross-Country race_type_Haies  race_type_Monté  race_type_Plat  \\\n",
      "0                   False           False            False            True   \n",
      "1                   False           False            False            True   \n",
      "2                   False           False            False            True   \n",
      "3                   False           False            False            True   \n",
      "4                   False           False            False            True   \n",
      "\n",
      "  race_type_Steeple race_type_Steeple-chase  \n",
      "0             False                   False  \n",
      "1             False                   False  \n",
      "2             False                   False  \n",
      "3             False                   False  \n",
      "4             False                   False  \n",
      "\n",
      "[5 rows x 121182 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical variables\n",
    "merged_df_encoded = pd.get_dummies(\n",
    "    merged_df, \n",
    "    columns=['sex', 'jockey', 'trainer', 'music', 'race_name', 'horse_name', 'race_type'], \n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# Check the new DataFrame shape and first few rows\n",
    "print(merged_df_encoded.shape)\n",
    "print(merged_df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75162 entries, 0 to 75161\n",
      "Columns: 121182 entries, horse_id to race_type_Steeple-chase\n",
      "dtypes: bool(121148), category(2), datetime64[ns](2), float64(10), int32(1), int64(10), object(9)\n",
      "memory usage: 8.5+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(merged_df_encoded.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['horse_id', 'race_id', 'number', 'age', 'handicap_weight',\n",
      "       'win_odd_live', 'reference_odd', 'min_place_odd', 'max_place_odd',\n",
      "       'ze_show_odd',\n",
      "       ...\n",
      "       'horse_name_ZWIALH', 'horse_name_ZYGARDE', 'horse_name_ZYGFRYD',\n",
      "       'race_type_Cross', 'race_type_Cross-Country', 'race_type_Haies',\n",
      "       'race_type_Monté', 'race_type_Plat', 'race_type_Steeple',\n",
      "       'race_type_Steeple-chase'],\n",
      "      dtype='object', length=121182)\n"
     ]
    }
   ],
   "source": [
    "print(merged_df_encoded.columns)  # Check which columns remain after dropping duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you want to standardize certain features\n",
    "scaler = StandardScaler()\n",
    "scaled_columns = ['handicap_weight', 'win_odd_live', 'reference_odd', \n",
    "                  'min_place_odd', 'max_place_odd', 'ze_show_odd', \n",
    "                  'ze_4th_odd', 'corde', 'position', 'distance', 'prize', \n",
    "                  '5th', '6th', '7th']\n",
    "merged_df_encoded[scaled_columns] = scaler.fit_transform(merged_df_encoded[scaled_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Predict 'position' as the target variable\n",
    "X = merged_df_encoded.drop(columns=['position'])  # Drop the target column from features\n",
    "y = merged_df_encoded['position']  # Target column for prediction\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.72 GiB for an array with shape (38921, 75162) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert categorical variables into dummy/indicator variables (one-hot encoding)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Now, you can train the model using the encoded data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X_train_encoded, X_test_encoded, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_encoded, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\reshape\\encoding.py:205\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    201\u001b[0m     with_dummies \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mdrop(columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# Encoding only object and category dtype columns. Get remaining\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;66;03m# columns to prepend to result.\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m     with_dummies \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes_to_encode\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, pre, sep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode\u001b[38;5;241m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     dummy \u001b[38;5;241m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    210\u001b[0m         col[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    211\u001b[0m         prefix\u001b[38;5;241m=\u001b[39mpre,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    217\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame.select_dtypes\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   4866\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   4868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 4870\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   4871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:576\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    574\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 576\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\blocks.py:645\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    643\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 645\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.72 GiB for an array with shape (38921, 75162) and data type bool"
     ]
    }
   ],
   "source": [
    "# Convert categorical variables into dummy/indicator variables (one-hot encoding)\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Now, you can train the model using the encoded data\n",
    "X_train_encoded, X_test_encoded, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'H_59329'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:836\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[0;32m    835\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[1;32m--> 836\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[0;32m    838\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'H_59329'"
     ]
    }
   ],
   "source": [
    "# Import a classifier (e.g., DecisionTreeClassifier, RandomForestClassifier)\n",
    "from sklearn.ensemble import RandomForestClassifier  # or another suitable model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
